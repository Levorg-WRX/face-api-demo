<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8" />
  <title>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”è¨ºæ–­AI</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body { font-family: sans-serif; text-align: center; margin: 20px; }
    video, canvas { position: absolute; top: 0; left: 0; }
    #wrapper { position: relative; display: inline-block; }
    #result { margin-top: 280px; font-size: 1.2em; white-space: pre-line; }
  </style>
</head>
<body>
  <h2>ğŸ“¹ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”è¨ºæ–­ï¼ˆå¹´é½¢ãƒ»æ€§åˆ¥ãƒ»è¡¨æƒ…ï¼‰</h2>
  <div id="wrapper">
    <video id="video" width="320" height="240" autoplay muted></video>
    <canvas id="overlay" width="320" height="240"></canvas>
  </div>
  <div id="result">ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...</div>

  <script>
    const MODEL_URL = "https://levorg-wrx.github.io/face-api-host/models";
    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const result = document.getElementById("result");

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        video.srcObject = stream;
      } catch (err) {
        result.textContent = "âŒ ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸ";
        console.error(err);
      }
    }

    async function loadModels() {
      await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
      await faceapi.nets.ageGenderNet.loadFromUri(MODEL_URL);
      await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
      result.textContent = "ğŸ“· ã‚«ãƒ¡ãƒ©ã«é¡”ã‚’æ˜ ã—ã¦ãã ã•ã„...";
    }

    video.addEventListener("play", () => {
      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detection = await faceapi
          .detectSingleFace(video)
          .withAgeAndGender()
          .withFaceExpressions();

        if (detection) {
          const resizedDetections = faceapi.resizeResults(detection, displaySize);
          canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
          faceapi.draw.drawDetections(canvas, resizedDetections);

          const age = detection.age.toFixed(0);
          const gender = detection.gender === "male" ? "ç”·æ€§ã£ã½ã„" : "å¥³æ€§ã£ã½ã„";
          const exp = Object.entries(detection.expressions).sort((a, b) => b[1] - a[1])[0][0];

          result.textContent = `ğŸ‘¤ å¹´é½¢ï¼š${age}æ­³\nâš§ æ€§åˆ¥ï¼š${gender}\nğŸ˜Š è¡¨æƒ…ï¼š${exp}`;
        } else {
          result.textContent = "ğŸ‘€ é¡”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“";
          canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
        }
      }, 1000);
    });

    // èµ·å‹•
    Promise.all([
      loadModels(),
      setupCamera()
    ]);
  </script>
</body>
</html>
